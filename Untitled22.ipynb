{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anu\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#importing libareris\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "#For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# For Transforming our target vatiable\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#For preprocessing text data\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bugs.txt\n",
      "comments.txt\n",
      "complaints.txt\n",
      "meaningless.txt\n",
      "requests.txt\n"
     ]
    }
   ],
   "source": [
    "path1='bugs.txt'\n",
    "print(path1)\n",
    "path2='comments.txt'\n",
    "print(path2)\n",
    "path3='complaints.txt'\n",
    "print(path3)\n",
    "path4='meaningless.txt'\n",
    "print(path4)\n",
    "path5='requests.txt'\n",
    "print(path5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_data(path):\n",
    "    text_Body=[]\n",
    "    with open(path, \"r\", encoding='windows-1256') as f:\n",
    "        lines = f.readlines()\n",
    "            #print(lines) \n",
    "        text_Body.append(lines)\n",
    "    text_body_appended=[]\n",
    "    for i in range(0,len(text_Body[0])):\n",
    "        value=text_Body[0][i]\n",
    "        text_body_appended.append(value)\n",
    "    return text_body_appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugs=text_data(path1)\n",
    "comments=text_data(path2)\n",
    "complaints=text_data(path3)\n",
    "meaningless=text_data(path4)\n",
    "requests=text_data(path5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n",
      "1759\n",
      "950\n",
      "306\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "print(len(bugs))\n",
    "print(len(comments))\n",
    "print(len(complaints))\n",
    "print(len(meaningless))\n",
    "print(len(requests))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_frame(txt,category):\n",
    "    column_names=('text','Category')\n",
    "    df = pd.DataFrame(columns=column_names)\n",
    "    df['text']=txt\n",
    "    df['Category']=category\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data_frame(bugs,\"Bug\")\n",
    "data=data.append(data_frame(comments,\"comments\"))\n",
    "data=data.append(data_frame(complaints,\"complaints\"))\n",
    "data=data.append(data_frame(meaningless,\"meaningless\"))\n",
    "data=data.append(data_frame(requests,\"requests\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bug', 'comments', 'complaints', 'meaningless', 'requests'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Category'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning and prepocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove link starts with https\n",
    "data['text'] = data['text'].map(lambda x:re.sub('http.*','',str(x)))\n",
    "#removing data and time (numeric values)\n",
    "data['text'] = data['text'].map(lambda x:re.sub('[0-9]','',str(x)))\n",
    "#removing \\n\n",
    "data['text'] = data['text'].map(lambda x:re.sub('[\\\\n]','',str(x)))\n",
    "#removing some special characters\n",
    "data['text'] = data['text'].map(lambda x:re.sub('[#|*|$|:|\\\\|&]','',str(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = ['jan','january','february' 'feb', 'march', 'april', 'may', 'june','july','aug',\n",
    "                    'october','October','june','july','February','apr','Apr','february','jun','jul','feb','sep',\n",
    "                    'august','sept','september','oct','october','nov','november','dec','december','mar','november october','wasnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing train data\n",
    "#removing stopwords and tokenizing it.\n",
    "stop=stopwords.words('english')\n",
    "text=[]\n",
    "none=data['text'].map(lambda x:text.append(' '.join\n",
    "       ([word for word in str(x).strip().split() if not word in set(stop) and word not in my_stopwords])))\n",
    "tfid=TfidfVectorizer(strip_accents=None,lowercase=False,preprocessor=None)\n",
    "x_features=tfid.fit_transform(text).toarray()\n",
    "x_features=pd.DataFrame(x_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Vs All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing target variable\n",
    "target=data['Category']\n",
    "label=LabelEncoder()\n",
    "target=label.fit_transform(target)\n",
    "target=to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug</th>\n",
       "      <th>comments</th>\n",
       "      <th>complaints</th>\n",
       "      <th>meaningless</th>\n",
       "      <th>requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bug  comments  complaints  meaningless  requests\n",
       "0  1.0       0.0         0.0          0.0       0.0\n",
       "1  1.0       0.0         0.0          0.0       0.0\n",
       "2  1.0       0.0         0.0          0.0       0.0\n",
       "3  1.0       0.0         0.0          0.0       0.0\n",
       "4  1.0       0.0         0.0          0.0       0.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=pd.DataFrame(data=target,columns=['Bug', 'comments', 'complaints', 'meaningless', 'requests'])\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training with One Vs All(One VS Rest)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "logistic=lg(penalty='l2',solver='newton-cg',C=5,multi_class='ovr',max_iter=5000)#using multiclass as ovr(one vs rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Bugs vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200000000000001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=logistic,X=x_features.iloc[:144,:],y=target.iloc[:144,0],cv=5)\n",
    "\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training comments vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8645083969274807"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=logistic,X=x_features.iloc[100:2100,:],y=target.iloc[100:2100,1],cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-a37dc943bae6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpredicted\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier \n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "predicted= clf.predict(x_features)\n",
    "print(accuracy_score(y,predicted))\n",
    "\n",
    "clf = lg.logistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training complaints vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6124260355029586"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=logistic,X=x_features.iloc[1500:3500,:],y=target.iloc[1500:3500,2],cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training meaningless vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6941155718769857"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=logistic,X=x_features.iloc[2700:3300,:],y=target.iloc[2700:3300,3],cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training requests vs all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7230952380952381"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=logistic,X=x_features.iloc[-206:,:],y=target.iloc[-206:,4],cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing target variable\n",
    "y=data['Category']\n",
    "y=pd.DataFrame(y,columns=['Category'])\n",
    "y = y['Category'].map({'Bug':-2, 'comments':-1, 'complaints':0, 'meaningless':1, 'requests':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier()\n",
    "knn=KNeighborsClassifier(5)\n",
    "nbc=MultinomialNB()\n",
    "sv=SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.638879501321505"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=logistic,X=x_features,y=y,cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5981402218549288"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=rfc,X=x_features,y=y,cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5510969399418437"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=knn,X=x_features,y=y,cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55141238342693"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=sv,X=x_features,y=y,cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6009423888295495"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=cross_val_score(estimator=nbc,X=x_features,y=y,cv=5)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Calculation F1 score, Precision and recall and testing accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score for naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = naive_bayes.MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7326018808777429\n"
     ]
    }
   ],
   "source": [
    "#test accuracy of naive bayes\n",
    "clf.fit(x_features,y)\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "predicted= clf.predict(x_features)\n",
    "print(accuracy_score(y,predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -2       0.00      0.00      0.00        72\n",
      "         -1       0.70      0.99      0.82      1759\n",
      "          0       0.87      0.61      0.72       950\n",
      "          1       1.00      0.03      0.06       306\n",
      "          2       0.00      0.00      0.00       103\n",
      "\n",
      "avg / total       0.74      0.73      0.67      3190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,y_pred))\n",
    "#naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = neighbors.KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_features,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5623824451410658\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "predicted= clf.predict(x_features)\n",
    "print(accuracy_score(y,predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -2       0.00      0.00      0.00        72\n",
      "         -1       0.56      1.00      0.72      1759\n",
      "          0       1.00      0.02      0.04       950\n",
      "          1       1.00      0.06      0.11       306\n",
      "          2       0.00      0.00      0.00       103\n",
      "\n",
      "avg / total       0.70      0.56      0.42      3190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_features,y)y_pred = clf.predict(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -2       0.00      0.00      0.00        72\n",
      "         -1       0.55      1.00      0.71      1759\n",
      "          0       0.00      0.00      0.00       950\n",
      "          1       0.00      0.00      0.00       306\n",
      "          2       0.00      0.00      0.00       103\n",
      "\n",
      "avg / total       0.30      0.55      0.39      3190\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anu\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets dig deeper and apply Deep learning for better accuracy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3190, 5193)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing target variable\n",
    "target=data['Category']\n",
    "label=LabelEncoder()\n",
    "target=label.fit_transform(target)\n",
    "target=to_categorical(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bug</th>\n",
       "      <th>comments</th>\n",
       "      <th>complaints</th>\n",
       "      <th>meaningless</th>\n",
       "      <th>requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bug  comments  complaints  meaningless  requests\n",
       "0  1.0       0.0         0.0          0.0       0.0\n",
       "1  1.0       0.0         0.0          0.0       0.0\n",
       "2  1.0       0.0         0.0          0.0       0.0\n",
       "3  1.0       0.0         0.0          0.0       0.0\n",
       "4  1.0       0.0         0.0          0.0       0.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target=pd.DataFrame(data=target,columns=['Bug', 'comments', 'complaints', 'meaningless', 'requests'])\n",
    "target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=Sequential()\n",
    "#adding layers to ANN\n",
    "clf.add(Dense(units=2048,activation=\"relu\",kernel_initializer=\"uniform\",kernel_regularizer=regularizers.l2(0.001),input_dim=5193))\n",
    "clf.add(Dropout(0.2))\n",
    "#adding two more hidden layer to ANN\n",
    "clf.add(Dense(units=2048,activation=\"relu\",kernel_initializer=\"uniform\",kernel_regularizer=regularizers.l2(0.001)))\n",
    "clf.add(Dropout(0.2))\n",
    "clf.add(Dense(units=2048,activation=\"relu\",kernel_initializer=\"uniform\",kernel_regularizer=regularizers.l2(0.001)))\n",
    "clf.add(Dropout(0.2))\n",
    "#adding output layer\n",
    "clf.add(Dense(units=5,activation=\"softmax\",kernel_initializer=\"uniform\"))\n",
    "#compiling ANN\n",
    "clf.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "3190/3190 [==============================] - 55s 17ms/step - loss: 4.2228 - acc: 0.5724\n",
      "Epoch 2/24\n",
      "3190/3190 [==============================] - 49s 15ms/step - loss: 1.1306 - acc: 0.6981\n",
      "Epoch 3/24\n",
      "3190/3190 [==============================] - 49s 15ms/step - loss: 0.9071 - acc: 0.7950\n",
      "Epoch 4/24\n",
      "3190/3190 [==============================] - 52s 16ms/step - loss: 0.7818 - acc: 0.8423\n",
      "Epoch 5/24\n",
      "3190/3190 [==============================] - 55s 17ms/step - loss: 0.7148 - acc: 0.8567\n",
      "Epoch 6/24\n",
      "3190/3190 [==============================] - 51s 16ms/step - loss: 0.6611 - acc: 0.8768\n",
      "Epoch 7/24\n",
      "3190/3190 [==============================] - 49s 15ms/step - loss: 0.6097 - acc: 0.8887\n",
      "Epoch 8/24\n",
      "3190/3190 [==============================] - 50s 16ms/step - loss: 0.5657 - acc: 0.9056\n",
      "Epoch 9/24\n",
      "3190/3190 [==============================] - 50s 16ms/step - loss: 0.5270 - acc: 0.9069\n",
      "Epoch 10/24\n",
      "3190/3190 [==============================] - 51s 16ms/step - loss: 0.5041 - acc: 0.9016\n",
      "Epoch 11/24\n",
      "3190/3190 [==============================] - 51s 16ms/step - loss: 0.4895 - acc: 0.9144\n",
      "Epoch 12/24\n",
      "3190/3190 [==============================] - 52s 16ms/step - loss: 0.4637 - acc: 0.9179\n",
      "Epoch 13/24\n",
      "3190/3190 [==============================] - 47s 15ms/step - loss: 0.4448 - acc: 0.9266\n",
      "Epoch 14/24\n",
      "3190/3190 [==============================] - 49s 15ms/step - loss: 0.4361 - acc: 0.9260\n",
      "Epoch 15/24\n",
      "3190/3190 [==============================] - 47s 15ms/step - loss: 0.4259 - acc: 0.9197\n",
      "Epoch 16/24\n",
      "3190/3190 [==============================] - 48s 15ms/step - loss: 0.4072 - acc: 0.9270\n",
      "Epoch 17/24\n",
      "3190/3190 [==============================] - 49s 15ms/step - loss: 0.4142 - acc: 0.9276\n",
      "Epoch 18/24\n",
      "3190/3190 [==============================] - 51s 16ms/step - loss: 0.3812 - acc: 0.9348\n",
      "Epoch 19/24\n",
      "3190/3190 [==============================] - 50s 16ms/step - loss: 0.3722 - acc: 0.9373\n",
      "Epoch 20/24\n",
      "3190/3190 [==============================] - 49s 15ms/step - loss: 0.3797 - acc: 0.9298\n",
      "Epoch 21/24\n",
      "3190/3190 [==============================] - 50s 16ms/step - loss: 0.3661 - acc: 0.9335\n",
      "Epoch 22/24\n",
      "3190/3190 [==============================] - 52s 16ms/step - loss: 0.3577 - acc: 0.9323\n",
      "Epoch 23/24\n",
      "3190/3190 [==============================] - 48s 15ms/step - loss: 0.3395 - acc: 0.9423\n",
      "Epoch 24/24\n",
      "3190/3190 [==============================] - 49s 15ms/step - loss: 0.3373 - acc: 0.9317\n"
     ]
    }
   ],
   "source": [
    "#fitting ANN\n",
    "hist=clf.fit(x_features,target,batch_size=32,epochs=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation By Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy curves for training and validation \n",
    "fig, ax = plt.subplots(2,1)\n",
    "ax[0].plot(hist.history['loss'], color='b', label=\"Training loss\")\n",
    "legend = ax[0].legend(loc='best', shadow=True)\n",
    "\n",
    "ax[1].plot(hist.history['acc'], color='r', label=\"Training accuracy\")\n",
    "legend = ax[1].legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[\"A lot of the time my purchase won't show up.\\n\",\n",
    "      'There should be a Free Demo Mode :/\\n',\n",
    "      \"App constantly crashes and looks like it was designed in 2009... Have to open the app multiple times before I get to a login screen, usually receiving a 'not responding' error.\\n\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.DataFrame(test,columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove link starts with https\n",
    "test['text'] = test['text'].map(lambda x:re.sub('http.*','',str(x)))\n",
    "#removing data and time (numeric values)\n",
    "test['text'] = test['text'].map(lambda x:re.sub('[0-9]','',str(x)))\n",
    "#removing some special characters\n",
    "test['text'] = test['text'].map(lambda x:re.sub('[#|*|$|:|\\\\|&]','',str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data\n",
    "#removing stopwords and tokenizing it.\n",
    "stop=stopwords.words('english')\n",
    "text=[]\n",
    "none=test['text'].map(lambda x:text.append(' '.join\n",
    "       ([word for word in str(x).strip().split() if not word in set(stop)])))\n",
    "x_features_test=tfid.transform(text).toarray()\n",
    "x_features_test=pd.DataFrame(x_features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting by ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=clf.predict(x_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 2], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select the indix with the maximum probability\n",
    "results = np.argmax(results,axis = 1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.DataFrame(results,columns=['Category'])\n",
    "int_category={0:'Bug', 1:'comments', 2:'complaints', 3:'meaningless', 4:'requests'}\n",
    "results['Category']=results['Category'].apply(lambda x:int_category[x])\n",
    "results['text']=test['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complaints</td>\n",
       "      <td>A lot of the time my purchase won't show up.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>requests</td>\n",
       "      <td>There should be a Free Demo Mode /\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>complaints</td>\n",
       "      <td>App constantly crashes and looks like it was d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                               text\n",
       "0  complaints     A lot of the time my purchase won't show up.\\n\n",
       "1    requests               There should be a Free Demo Mode /\\n\n",
       "2  complaints  App constantly crashes and looks like it was d..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.save('feedback_clfr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
